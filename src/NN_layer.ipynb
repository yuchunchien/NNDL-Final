{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n",
      "WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import timeit\n",
    "import inspect\n",
    "import sys\n",
    "import numpy\n",
    "from theano.tensor.nnet import conv\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import downsample\n",
    "from theano.tensor.signal import pool\n",
    "\n",
    "from Project_nn import LogisticRegression, HiddenLayer, LeNetConvPoolLayer, train_nn\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "style_outputs[4] #(1,256,IMAGE_W/4, IMAGE_W/4)\n",
    "style_outputs[8] #(1,512,IMAGE_W/8, IMAGE_W/8)\n",
    "patch_size = 4\n",
    "stride = 2\n",
    "k_14 = ((Image_W/4 - patch_size+stride)/stride)\n",
    "features_4 = k_14*k_14\n",
    "k_18 = ((Image_W/8 - patch_size+stride)/stride)\n",
    "features_8 = k_18*k_18\n",
    "\n",
    "layer4_style = LeNetConvPoolLayer(\n",
    "    rng,\n",
    "    input=layer4.output,\n",
    "    image_shape=(1, 256, IMAGE_W/4, IMAGE_W/4), # (input batch size, number of input feature, heightm, width)\n",
    "    filter_shape=(features_4, 256, patch_size, patch_size),   # (number of output feature maps, number of input feature maps, height, width)\n",
    "    poolsize=(1, 1)\n",
    ")\n",
    "\n",
    "layer8_style = LeNetConvPoolLayer(\n",
    "    rng,\n",
    "    input=layer8.output,\n",
    "    image_shape=(1, 512, IMAGE_W/8, IMAGE_W/8), # (input batch size, number of input feature, heightm, width)\n",
    "    filter_shape=(features_8, 512, patch_size, patch_size),   # (number of output feature maps, number of input feature maps, height, width)\n",
    "    poolsize=(1, 1)\n",
    ")\n",
    "for i in range(features_4)\n",
    "    w_4[i,:,:,:] = style_output[4][:,i/k_14:i/k_14+patch_size,i%k_14:i%k_14+patch_size]\n",
    "layer4_style.set_para(W=w_4, B=np.zeros((features_4,256),dtype = 'float32'))\n",
    "\n",
    "for i in range(features_8)\n",
    "    w_8[i,:,:,:] = style_output[8][:,i/k_18:i/k_18+patch_size,i%k_18:i%k_18+patch_size]\n",
    "layer8_style.set_para(W=w_8, B=np.zeros((features_8,512),dtype = 'float32'))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "values = pickle.load(open('../../vgg19_normalized.pkl'))['param values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
